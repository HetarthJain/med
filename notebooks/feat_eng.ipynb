{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv(\"../csv/merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the target feature using ratings \n",
    "# here 1 represents positive and 0 - represents negative\n",
    "data['review_sentiment'] = data['rating'].apply(lambda x: 1 if x > 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>review_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8</td>\n",
       "      <td>3-Nov-15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>27-Nov-16</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID                  drugName                     condition  \\\n",
       "0    206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1     95260                Guanfacine                          ADHD   \n",
       "2     92703                    Lybrel                 Birth Control   \n",
       "3    138000                Ortho Evra                 Birth Control   \n",
       "4     35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "\n",
       "                                              review  rating       date  \\\n",
       "0  \"It has no side effect, I take it in combinati...       9  20-May-12   \n",
       "1  \"My son is halfway through his fourth week of ...       8  27-Apr-10   \n",
       "2  \"I used to take another oral contraceptive, wh...       5  14-Dec-09   \n",
       "3  \"This is my first time using any form of birth...       8   3-Nov-15   \n",
       "4  \"Suboxone has completely turned my life around...       9  27-Nov-16   \n",
       "\n",
       "   usefulCount  review_sentiment  \n",
       "0           27                 1  \n",
       "1          192                 1  \n",
       "2           17                 0  \n",
       "3           10                 1  \n",
       "4           37                 1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def preprocess_text(text_data):\n",
    "\n",
    "    text_data = decontracted(text_data)\n",
    "    \n",
    "    text_data = text_data.replace('\\n',' ')\n",
    "    text_data = text_data.replace('\\r',' ')\n",
    "    text_data = text_data.replace('\\t',' ')\n",
    "    text_data = text_data.replace('-',' ')\n",
    "    text_data = text_data.replace(\"/\",' ')\n",
    "    text_data = text_data.replace(\">\",' ')\n",
    "    text_data = text_data.replace('\"',' ')\n",
    "    text_data = text_data.replace('?',' ')\n",
    "    return text_data\n",
    "  \n",
    "# loading stop words from nltk library\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "#removing 'no' from the stop words list as there is an importance of 'side effects' and 'no side effects' in review\n",
    "stop_words.remove('no')\n",
    "\n",
    "def nlp_preprocessing(review):\n",
    "    '''This functional block preprocess the text data by removing digits, extra spaces, stop words \n",
    "    and converting words to lower case and stemming words'''\n",
    "    \n",
    "    if type(review) is not int:\n",
    "        string = \"\"\n",
    "        review = preprocess_text(review)\n",
    "        review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "        review = re.sub('\\s+',' ', review)\n",
    "        review = review.lower()\n",
    "        for word in review.split():\n",
    "            if not word in stop_words:\n",
    "                word = stemmer.stem(word)\n",
    "                string += word + \" \"\n",
    "        return string \n",
    "      \n",
    "data['cleaned_review'] = data['review'].apply(nlp_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['drugName'] = data['drugName'].apply(lambda x:x.lower()) # converting to lower case\n",
    "data['condition'] = data['condition'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sent = SentimentIntensityAnalyzer()\n",
    "data[\"sentiment_score\"] = [sent.polarity_scores(r)['compound'] for r in data['review']]\n",
    "data['sentiment_score_clean'] = [sent.polarity_scores(r)['compound'] for r in data['cleaned_review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hetar\\AppData\\Local\\Temp\\ipykernel_10148\\4136641825.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['date'] = pd.to_datetime(data['date'])\n",
      "c:\\Users\\hetar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\hetar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Adding the year as feature \n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data['year'] = data['date'].dt.year\n",
    "\n",
    "#Word count in each review\n",
    "data['word_count']=data[\"cleaned_review\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "#Unique word count \n",
    "data['unique_word_count']=data[\"cleaned_review\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "#character count\n",
    "data['char_length']=data[\"cleaned_review\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "#punctuation count\n",
    "data[\"count_punctuations\"] = data[\"review\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "#Number of stopwords\n",
    "data[\"stopword_count\"] = data[\"review\"].apply(lambda x: len([w for w in str(x).lower().split() if w in stop_words]))\n",
    "\n",
    "#Average length of the words\n",
    "data[\"mean_word_len\"] = data[\"cleaned_review\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212698, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>review_sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_score_clean</th>\n",
       "      <th>year</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>char_length</th>\n",
       "      <th>count_punctuations</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>mean_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>valsartan</td>\n",
       "      <td>left ventricular dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>2012-05-20</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>no side effect take combin bystol mg fish oil</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>guanfacine</td>\n",
       "      <td>adhd</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-04-27</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>son halfway fourth week intuniv becam concern ...</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>2010</td>\n",
       "      <td>65</td>\n",
       "      <td>54</td>\n",
       "      <td>372</td>\n",
       "      <td>23</td>\n",
       "      <td>69</td>\n",
       "      <td>4.723077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>lybrel</td>\n",
       "      <td>birth control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>2009-12-14</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>use take anoth oral contracept pill cycl happi...</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>2009</td>\n",
       "      <td>70</td>\n",
       "      <td>49</td>\n",
       "      <td>403</td>\n",
       "      <td>34</td>\n",
       "      <td>58</td>\n",
       "      <td>4.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138000</td>\n",
       "      <td>ortho evra</td>\n",
       "      <td>birth control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-11-03</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>first time use form birth control glad went pa...</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>2015</td>\n",
       "      <td>39</td>\n",
       "      <td>26</td>\n",
       "      <td>226</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>4.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35696</td>\n",
       "      <td>buprenorphine / naloxone</td>\n",
       "      <td>opiate dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-11-27</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>suboxon complet turn life around feel healthie...</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>0.8934</td>\n",
       "      <td>2016</td>\n",
       "      <td>59</td>\n",
       "      <td>52</td>\n",
       "      <td>381</td>\n",
       "      <td>28</td>\n",
       "      <td>60</td>\n",
       "      <td>5.457627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID                  drugName                     condition  \\\n",
       "0    206461                 valsartan  left ventricular dysfunction   \n",
       "1     95260                guanfacine                          adhd   \n",
       "2     92703                    lybrel                 birth control   \n",
       "3    138000                ortho evra                 birth control   \n",
       "4     35696  buprenorphine / naloxone             opiate dependence   \n",
       "\n",
       "                                              review  rating       date  \\\n",
       "0  \"It has no side effect, I take it in combinati...       9 2012-05-20   \n",
       "1  \"My son is halfway through his fourth week of ...       8 2010-04-27   \n",
       "2  \"I used to take another oral contraceptive, wh...       5 2009-12-14   \n",
       "3  \"This is my first time using any form of birth...       8 2015-11-03   \n",
       "4  \"Suboxone has completely turned my life around...       9 2016-11-27   \n",
       "\n",
       "   usefulCount  review_sentiment  \\\n",
       "0           27                 1   \n",
       "1          192                 1   \n",
       "2           17                 0   \n",
       "3           10                 1   \n",
       "4           37                 1   \n",
       "\n",
       "                                      cleaned_review  sentiment_score  \\\n",
       "0     no side effect take combin bystol mg fish oil           -0.2960   \n",
       "1  son halfway fourth week intuniv becam concern ...           0.8603   \n",
       "2  use take anoth oral contracept pill cycl happi...           0.7962   \n",
       "3  first time use form birth control glad went pa...           0.7184   \n",
       "4  suboxon complet turn life around feel healthie...           0.9403   \n",
       "\n",
       "   sentiment_score_clean  year  word_count  unique_word_count  char_length  \\\n",
       "0                -0.2960  2012           9                  9           46   \n",
       "1                 0.6929  2010          65                 54          372   \n",
       "2                 0.2732  2009          70                 49          403   \n",
       "3                 0.1027  2015          39                 26          226   \n",
       "4                 0.8934  2016          59                 52          381   \n",
       "\n",
       "   count_punctuations  stopword_count  mean_word_len  \n",
       "0                   3               6       4.111111  \n",
       "1                  23              69       4.723077  \n",
       "2                  34              58       4.757143  \n",
       "3                  15              45       4.794872  \n",
       "4                  28              60       5.457627  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracing the subject and object count for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def subj_obj_count(review):\n",
    "\n",
    "    sen = review\n",
    "    doc=nlp(sen)\n",
    "    sub_words = set([str(word) for word in doc if (word.dep_ == \"nsubj\")])\n",
    "\n",
    "    obj_words = set([str(word) for word in doc if (word.dep_ == \"dobj\")])\n",
    "\n",
    "    return len(sub_words),len(obj_words)\n",
    "\n",
    "# count = []\n",
    "\n",
    "# for r in data['review']:\n",
    "#     count.append(subj_obj_count(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_obj = pd.DataFrame(count,columns=['subj_count','obj_count'])\n",
    "# sub_obj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212698, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_count</th>\n",
       "      <th>obj_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subj_count  obj_count\n",
       "0           2          2\n",
       "1           9          5\n",
       "2          10          8\n",
       "3           8          5\n",
       "4           8         10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sub_obj.to_csv('sub_obj.csv',index=False)\n",
    "sub_obj = pd.read_csv('../csv/sub_obj.csv')\n",
    "print(sub_obj.shape)\n",
    "sub_obj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ner_lst = nlp.pipe_labels['ner']\n",
    "\n",
    "def ner(review):\n",
    "\tr = review\n",
    "\tdoc = nlp(r)\n",
    "\tdic = {}.fromkeys(ner_lst,0)\n",
    "\tfor word in doc.ents:\n",
    "\t\tdic[word.label_]+=1\n",
    "\treturn dic\n",
    "# entity = [ner(r) for r in data['cleaned_review']]\n",
    "# entity = pd.DataFrame(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212698, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDINAL</th>\n",
       "      <th>DATE</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>FAC</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>LAW</th>\n",
       "      <th>LOC</th>\n",
       "      <th>MONEY</th>\n",
       "      <th>NORP</th>\n",
       "      <th>ORDINAL</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PERCENT</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>TIME</th>\n",
       "      <th>WORK_OF_ART</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CARDINAL  DATE  EVENT  FAC  GPE  LANGUAGE  LAW  LOC  MONEY  NORP  ORDINAL  \\\n",
       "0         0     0      0    0    0         0    0    0      0     0        0   \n",
       "1         1     4      0    0    0         0    0    0      0     0        0   \n",
       "2         0     4      0    0    0         0    0    0      0     0        2   \n",
       "3         0     2      0    0    0         0    0    0      0     0        1   \n",
       "4         0     0      0    0    0         0    0    0      0     0        0   \n",
       "\n",
       "   ORG  PERCENT  PERSON  PRODUCT  QUANTITY  TIME  WORK_OF_ART  \n",
       "0    0        0       0        0         0     0            0  \n",
       "1    0        0       0        0         0     1            0  \n",
       "2    0        0       0        0         0     0            0  \n",
       "3    0        0       1        0         0     0            0  \n",
       "4    2        0       0        0         0     0            0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entity.to_csv('entities.csv',index=False)\n",
    "entity = pd.read_csv('../csv/entities.csv')\n",
    "print(entity.shape)\n",
    "entity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling\n",
    "Analyses text data and finds the topics that best describes the set of documents.\n",
    "#### Latent Dirichlet Allocation (LDA) \n",
    "A popular form of statistical topic modelling. \n",
    "It is used to classify the text in a document to a particular topic. The words are allocated to the topic with their distribution using Dirichlet distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim\n",
    "# # preprocess corpus for unigram in a cleaned reviews\n",
    "# corpus = data['cleaned_review']\n",
    "# lst_corpus=[]\n",
    "# for string in tqdm(corpus):\n",
    "# \tlst_words = string.split()\n",
    "# \tlst_grams = [\" \".join(lst_words[i:i+1]) for i in range(0, len(lst_words),1)]\n",
    "# \tlst_corpus.append(lst_grams)\n",
    "\n",
    "# # lst_corpus is the list of documents. Each document in lst_corpus is a list of words from a review.\n",
    "# lst_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary maps every unique word in the corpus to a unique integer ID and its frequency in the document. This is a common format for text data in many natural language processing tasks.\n",
    "# id2word = gensim.corpora.Dictionary(lst_corpus)\n",
    "# id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic_corpus = [id2word.doc2bow(word) for word in lst_corpus]\n",
    "# dic_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LDA model` is a generative statistical model that allows sets of observations to be explained by unobserved groups. In the case of text data, these `unobserved groups are topics`, and the `observations are words`. <br><br>\n",
    "The LDA model assumes that each document in the corpus is a mixture of a small number of topics and that each word in the document is attributable to one of the document's topics. The model learns these topics and their distribution over the documents in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a Latent Dirichlet Allocation (LDA) model on this \n",
    "# lda_model = gensim.models.LdaModel(corpus = dic_corpus, id2word=id2word)\n",
    "# lda_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_document_topics` method of the `gensim` librarys LDA model to get the topic distribution for a specific document in the corpus.<br><br>\n",
    "\n",
    "The `get_document_topics` method takes a document in bag-of-words (BoW) format and returns a list of tuples, where each tuple contains a topics ID and the probability that was assigned to it. The document is represented by `dic_corpus[i]`, where `[i]` is the index of the document in the `dic_corpus` list.\n",
    "<br><br>\n",
    "\n",
    "The `minimum_probability` parameter is set to 0.0. This means that all topics will be included in the output, even those with a very low assigned probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_vecs = []\n",
    "# for i in range(len(corpus)):\n",
    "# \ttop_topics = (lda_model.get_document_topics(dic_corpus[i],minimum_probability=0.0))\n",
    "\n",
    "# \ttopic_vec = [top_topics[i][1] for i in range(20)]\n",
    "\n",
    "# \ttrain_vecs.append(topic_vec)\n",
    "\n",
    "# topics = pd.DataFrame(train_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212698, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.036646</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.029631</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.037755</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.014679</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.027342</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.017766</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.019721</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.023106</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.001000  0.001000  0.001000  0.001000  0.001000  0.001000  0.001000   \n",
       "1  0.000154  0.000154  0.000154  0.000154  0.000154  0.000154  0.000154   \n",
       "2  0.000143  0.000143  0.000143  0.000143  0.000143  0.029631  0.000143   \n",
       "3  0.000250  0.000250  0.000250  0.000250  0.000250  0.000250  0.000250   \n",
       "4  0.000172  0.000172  0.000172  0.000172  0.000172  0.017766  0.000172   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0  0.001000  0.001000  0.001000  0.001000  0.001000  0.001000  0.001000   \n",
       "1  0.000154  0.000154  0.000154  0.000154  0.000154  0.000154  0.000154   \n",
       "2  0.000143  0.037755  0.000143  0.000143  0.000143  0.000143  0.000143   \n",
       "3  0.000250  0.000250  0.000250  0.000250  0.000250  0.000250  0.000250   \n",
       "4  0.000172  0.019721  0.000172  0.000172  0.000172  0.000172  0.000172   \n",
       "\n",
       "         14        15        16        17        18        19  \n",
       "0  0.001000  0.001000  0.001000  0.001000  0.001000  0.001000  \n",
       "1  0.000154  0.036646  0.000154  0.000154  0.000154  0.000154  \n",
       "2  0.000143  0.000143  0.000143  0.000143  0.014679  0.000143  \n",
       "3  0.000250  0.000250  0.027342  0.000250  0.000250  0.000250  \n",
       "4  0.023106  0.000172  0.000172  0.000172  0.000172  0.000172  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics.to_csv('topics.csv',index=False)\n",
    "topics = pd.read_csv('../csv/topics.csv')\n",
    "# print(\"\\nBefore modifying first column:\\n\", topics.columns) \n",
    "# topics.rename(columns = {i:str(i) for i in range(0,topics.shape[1])}, inplace = True) \n",
    "# print(\"\\nAfter modifying first column:\\n\", topics.columns) \n",
    "print(topics.shape)\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212698, 58)\n"
     ]
    }
   ],
   "source": [
    "# Now combining the features extracted above - subject object count,named entity recognition,topic modelling vectors for each of the review.\n",
    "data = pd.concat([data,sub_obj,entity,topics],axis=1)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uniqueID', 'drugName', 'condition', 'review', 'rating', 'date',\n",
       "       'usefulCount', 'review_sentiment', 'cleaned_review', 'sentiment_score',\n",
       "       'sentiment_score_clean', 'year', 'word_count', 'unique_word_count',\n",
       "       'char_length', 'count_punctuations', 'stopword_count', 'mean_word_len',\n",
       "       'subj_count', 'obj_count', 'CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE',\n",
       "       'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT',\n",
       "       'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART', '0', '1', '2',\n",
       "       '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15',\n",
       "       '16', '17', '18', '19'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212690, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>review_sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>valsartan</td>\n",
       "      <td>left ventricular dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>2012-05-20</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>no side effect take combin bystol mg fish oil</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>guanfacine</td>\n",
       "      <td>adhd</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-04-27</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>son halfway fourth week intuniv becam concern ...</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.036646</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>lybrel</td>\n",
       "      <td>birth control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>2009-12-14</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>use take anoth oral contracept pill cycl happi...</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.014679</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138000</td>\n",
       "      <td>ortho evra</td>\n",
       "      <td>birth control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-11-03</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>first time use form birth control glad went pa...</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.027342</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35696</td>\n",
       "      <td>buprenorphine / naloxone</td>\n",
       "      <td>opiate dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-11-27</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>suboxon complet turn life around feel healthie...</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.023106</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID                  drugName                     condition  \\\n",
       "0    206461                 valsartan  left ventricular dysfunction   \n",
       "1     95260                guanfacine                          adhd   \n",
       "2     92703                    lybrel                 birth control   \n",
       "3    138000                ortho evra                 birth control   \n",
       "4     35696  buprenorphine / naloxone             opiate dependence   \n",
       "\n",
       "                                              review  rating       date  \\\n",
       "0  \"It has no side effect, I take it in combinati...       9 2012-05-20   \n",
       "1  \"My son is halfway through his fourth week of ...       8 2010-04-27   \n",
       "2  \"I used to take another oral contraceptive, wh...       5 2009-12-14   \n",
       "3  \"This is my first time using any form of birth...       8 2015-11-03   \n",
       "4  \"Suboxone has completely turned my life around...       9 2016-11-27   \n",
       "\n",
       "   usefulCount  review_sentiment  \\\n",
       "0           27                 1   \n",
       "1          192                 1   \n",
       "2           17                 0   \n",
       "3           10                 1   \n",
       "4           37                 1   \n",
       "\n",
       "                                      cleaned_review  sentiment_score  ...  \\\n",
       "0     no side effect take combin bystol mg fish oil           -0.2960  ...   \n",
       "1  son halfway fourth week intuniv becam concern ...           0.8603  ...   \n",
       "2  use take anoth oral contracept pill cycl happi...           0.7962  ...   \n",
       "3  first time use form birth control glad went pa...           0.7184  ...   \n",
       "4  suboxon complet turn life around feel healthie...           0.9403  ...   \n",
       "\n",
       "         10        11        12        13        14        15        16  \\\n",
       "0  0.001000  0.001000  0.001000  0.001000  0.001000  0.001000  0.001000   \n",
       "1  0.000154  0.000154  0.000154  0.000154  0.000154  0.036646  0.000154   \n",
       "2  0.000143  0.000143  0.000143  0.000143  0.000143  0.000143  0.000143   \n",
       "3  0.000250  0.000250  0.000250  0.000250  0.000250  0.000250  0.027342   \n",
       "4  0.000172  0.000172  0.000172  0.000172  0.023106  0.000172  0.000172   \n",
       "\n",
       "         17        18        19  \n",
       "0  0.001000  0.001000  0.001000  \n",
       "1  0.000154  0.000154  0.000154  \n",
       "2  0.000143  0.014679  0.000143  \n",
       "3  0.000250  0.000250  0.000250  \n",
       "4  0.000172  0.000172  0.000172  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../csv/final_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
